# -*- coding: utf-8 -*-
"""
Created on Thu Mar 8 13:07:32 2022

@author: Bagoly Zolt√°n
"""

import os
import math
import numpy as np
import tqdm as my_tqdm
import matplotlib.pyplot as plt
from matplotlib import style
import torch
import torch.nn as nn
import torch.nn.functional as F
import time

NET_TYPE =   "fully connected"   # "convolutional" or "fully connected"
device = torch.device("cpu")

# adat elokeszites
LEN_OF_SEGMENTS = 400
LEN_OF_INPUT = 4 * LEN_OF_SEGMENTS
LEN_OF_OUTPUT = 5 * LEN_OF_SEGMENTS

shuffled_training_data = np.load("my_training_data_1d_XYVO_better_skale.npy", allow_pickle=True)
shuffled_testing_data = np.load("my_testing_data_1d_XYVO_better_skale.npy", allow_pickle=True)
my_X = torch.Tensor([i[0] for i in shuffled_training_data]).view(-1, LEN_OF_INPUT)
my_X_t = torch.Tensor([i[0] for i in shuffled_testing_data]).view(-1, LEN_OF_INPUT)
my_y = torch.Tensor([i[1] for i in shuffled_training_data]).view(-1, LEN_OF_OUTPUT)
my_y_t = torch.Tensor([i[1] for i in shuffled_testing_data]).view(-1, LEN_OF_OUTPUT)
my_test_X_l = my_X_t
my_test_y_l = my_y_t
my_train_X_l = my_X
my_train_y_l = my_y

my_test_X, my_test_y, my_train_X, my_train_y = my_test_X_l, my_test_y_l, my_train_X_l, my_train_y_l

# GPU
def on_gpu():
    if torch.cuda.is_available():
        return torch.device("cuda:0")
    else:
        return torch.device("cpu")

device = on_gpu()
print(device)

# Net convolutional
class Net_conv(nn.Module):
    def __init__(self):
        super().__init__()
        
        self.conv1 = nn.Conv1d(1, 32, kernel_size=4, stride=4)
        nn.init.kaiming_uniform_(self.conv1.weight, mode='fan_in', nonlinearity='relu')
        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, dilation=1, padding=2)
        nn.init.kaiming_uniform_(self.conv2.weight, mode='fan_in', nonlinearity='relu')
        self.conv3 = nn.Conv1d(64, 64, kernel_size=5, dilation=1, padding=2)
        nn.init.kaiming_uniform_(self.conv3.weight, mode='fan_in', nonlinearity='relu')
        self.conv4 = nn.Conv1d(64, 64, kernel_size=5, dilation=1, padding=2)
        nn.init.kaiming_uniform_(self.conv4.weight, mode='fan_in', nonlinearity='relu')
        self.conv5 = nn.Conv1d(64, 64, kernel_size=5, dilation=1, padding=2)
        nn.init.kaiming_uniform_(self.conv5.weight, mode='fan_in', nonlinearity='relu')
        
        self.conv6 = nn.Conv1d(16, 128, kernel_size=5, dilation=1, padding=2)
        nn.init.kaiming_uniform_(self.conv6.weight, mode='fan_in', nonlinearity='relu')
        self.conv7 = nn.Conv1d(128, 64, kernel_size=5, dilation=1, padding=2)
        nn.init.kaiming_uniform_(self.conv7.weight, mode='fan_in', nonlinearity='relu')
        
        x = torch.randn(LEN_OF_INPUT).view(-1, 1, LEN_OF_INPUT)
        self._to_linear = None
        self.convs(x)
        
        self.fc1 = nn.Linear(self._to_linear, 512)
        nn.init.kaiming_uniform_(self.fc1.weight, mode='fan_in', nonlinearity='relu')
        self.fc2 = nn.Linear(512, LEN_OF_OUTPUT)
        nn.init.kaiming_uniform_(self.fc2.weight, mode='fan_in', nonlinearity='relu')
        
    def convs(self, x):
        x = F.max_pool1d(F.relu(self.conv1(x)), (3))
        #print("\n")
        #print("1", x[0].shape, x[0], x)
        x = F.max_pool1d(F.relu(self.conv2(x)), (3))
        #print("2", x[0].shape, x[0], x)
        x = F.max_pool1d(F.relu(self.conv3(x)), (3))
        #x = F.max_pool1d(F.relu(self.conv4(x)), (3))
        #x = F.max_pool1d(F.relu(self.conv5(x)), (3))
        #x = F.max_pool1d(F.relu(self.conv6(x)), (3))
        #x = F.max_pool1d(F.relu(self.conv7(x)), (3))
        # hat ezt kiszamolni nem lett volna konnyu. Ezert kell kiprobalni random adattal
        
        if self._to_linear == None:
            self._to_linear = x[0].shape[0] * x[0].shape[1]

        return x
        
    def forward(self, x):
        # print(self.only_linear)
        x = self.convs(x)
        # print("3", x.shape, x[0], x)
        
        x = x.view(-1, self._to_linear)
        # print("4", x.shape, x[0], x)
        
        x = F.relu(self.fc1(x))
        # print("5", x.shape, x[0], x)
                
        x = self.fc2(x)
        # print("6", x.shape, x[0], x)
        
        return x

# Net fully connected
class Net_fc(nn.Module):
    def __init__(self):
        super().__init__()
        
        x = torch.randn(LEN_OF_INPUT).view(-1, 1, LEN_OF_INPUT)
        self._to_linear = None
        self.linearize(x)
        
        self.fc1 = nn.Linear(self._to_linear, 512)
        nn.init.kaiming_uniform_(self.fc1.weight, mode='fan_in', nonlinearity='relu')
        self.fc2 = nn.Linear(512, 1024)
        nn.init.kaiming_uniform_(self.fc2.weight, mode='fan_in', nonlinearity='relu')
        self.fc3 = nn.Linear(1024, 1024)
        nn.init.kaiming_uniform_(self.fc3.weight, mode='fan_in', nonlinearity='relu')
        self.fc4 = nn.Linear(1024, 512)
        nn.init.kaiming_uniform_(self.fc4.weight, mode='fan_in', nonlinearity='relu')
        self.fc5 = nn.Linear(512, 512)
        nn.init.kaiming_uniform_(self.fc5.weight, mode='fan_in', nonlinearity='relu')
        self.fc6 = nn.Linear(512, 512)
        nn.init.kaiming_uniform_(self.fc6.weight, mode='fan_in', nonlinearity='relu')
        self.fc_last = nn.Linear(512, LEN_OF_OUTPUT)
        nn.init.kaiming_uniform_(self.fc_last.weight, mode='fan_in', nonlinearity='relu')
                
    def linearize(self, x):
        if self._to_linear == None:
            self._to_linear = x[0].shape[0] * x[0].shape[1]

        return x
        
    def forward(self, x):
        # print("33", x.shape, x[0], x)
        
        x = x.view(-1, self._to_linear)
        # print("4", x.shape, x[0], x)
        
        x = F.relu(self.fc1(x))
        # print("5", x.shape, x[0], x)
        
        x = F.relu(self.fc2(x))
        # print("6", x.shape, x[0], x)
        
        x = F.relu(self.fc3(x))
        # print("7", x.shape, x[0], x)
        
        x = F.relu(self.fc4(x))
        # print("8", x.shape, x[0], x)
        
        x = F.relu(self.fc5(x))
        # print("9", x.shape, x[0], x)
        
        x = F.relu(self.fc6(x))
        # print("10", x.shape, x[0], x)
        
        x = self.fc_last(x)
        # print("last", x.shape, x[0], x)
        
        return x

loss_function = nn.MSELoss()

path = 'net_164751322101013.pth'
if os.path.isfile(path):
    print("helyes filenev:", path)
    
    net = torch.load(os.path.join(path))
    print(net)
    net.eval()
def load_net(path_param):
    if os.path.isfile(path):
        print("helyes filenev:", path_param)
        
        net = torch.load(os.path.join(path_param))
        print(net)
        net.eval()
    
def my_test(size=32, print_now=False):
    # print(my_test_X.shape, my_test_X)
    # print("len(my_test_X)", len(my_test_X))
    # print(size)
    random_start = np.random.randint(len(my_test_X) - size)
    
    my_X2, my_y2 = my_test_X[random_start : random_start + size], my_test_y[random_start : random_start + size]
    net.eval()
    with torch.no_grad():
        val_acc, val_loss = my_fwd_pass(my_X2.view(-1, 1, LEN_OF_INPUT).to(device), my_y2.to(device), train=False)
    if(print_now):
        print("Val loss: ", val_loss, "; Val_acc: ", val_acc)
    net.train()
    return val_acc, val_loss

def my_fwd_pass(b_x, b_y, train=False):
    if train == True:
        net.zero_grad()
    #print("b_x", b_x.shape)
    #print("b_y:", b_y.shape)
    outputs = net(b_x)
    #print("outputs: ", outputs.shape, outputs)
    # if train == False:
        # print("outputs:", outputs, "\nb_y:", b_y)
    # a matches-t maskepp kene szamolni
    matches = [abs(torch.argmax(i) - torch.argmax(j)) < 0.1 for i, j in zip(outputs, b_y)]
    accuracy = matches.count(True) / len(matches)
    loss = loss_function(outputs, b_y)

    # with open("efop_log_output_of_net.log", "a") as file:
    #     # for i in range(len(outputs)):
    #     #     output = outputs[0][i]
    #     file.write(f"{MODEL_NAME},{round(time.time(),3)},{round(float(outputs),10)}\n")
    #     file.write(f"{MODEL_NAME},{round(time.time(),3)},{round(float(loss),15)}\n")
    return accuracy, loss

# Vizualizalasa a tanitott halo mukodesenek
style.use("ggplot")
    
#create_acc_loss_graph(model_name)

def one_segment__test(start):
    # print(start)
    my_X3, my_y3 = my_test_X[start : start + 1], my_test_y[start : start + 1]
    to_show_wanted = my_y3.to(device)
    to_show_guessed = net(my_X3.view(-1, 1, LEN_OF_INPUT).to(device))
    # print(to_show_wanted.shape)
    # print(to_show_guessed.shape)
    # print(" Target:", to_show_wanted, "\n", "Guess:", to_show_guessed)
    return to_show_wanted, to_show_guessed
def one_segment__train(start):
    # print(start)
    my_X3, my_y3 = my_train_X[start : start + 1], my_train_y[start : start + 1]
    to_show_wanted = my_y3.to(device)
    to_show_guessed = net(my_X3.view(-1, 1, LEN_OF_INPUT).to(device))
    # print(to_show_wanted.shape)
    # print(to_show_guessed.shape)
    # print(" Target:", to_show_wanted, "\n", "Guess:", to_show_guessed)
    return to_show_wanted, to_show_guessed

def lets_see(to_show_wanted_, to_show_guessed_):
    FL_w = []
    FR_w = []
    RL_w = []
    RR_w = []
    SW_w = []
    
    FL_g = []
    FR_g = []
    RL_g = []
    RR_g = []
    SW_g = []
    
    FL_w_ = []
    FR_w_ = []
    RL_w_ = []
    RR_w_ = []
    SW_w_ = []
    
    FL_g_ = []
    FR_g_ = []
    RL_g_ = []
    RR_g_ = []
    SW_g_ = []
        
    for i in range(LEN_OF_OUTPUT):
        if (i % 5) == 0:
            FL_w.append(float(to_show_wanted_[0][i]) * 1700)
            FL_g.append(float(to_show_guessed_[0][i]) * 1700)
            FL_w_.append(float(to_show_wanted_[0][i]))
            FL_g_.append(float(to_show_guessed_[0][i]))
        if (i % 5) == 1:
            FR_w.append(float(to_show_wanted_[0][i]) * 1700)
            FR_g.append(float(to_show_guessed_[0][i]) * 1700)
            FR_w_.append(float(to_show_wanted_[0][i]))
            FR_g_.append(float(to_show_guessed_[0][i]))
        if (i % 5) == 2:    
            RL_w.append(float(to_show_wanted_[0][i]) * 1700)
            RL_g.append(float(to_show_guessed_[0][i]) * 1700)
            RL_w_.append(float(to_show_wanted_[0][i]))
            RL_g_.append(float(to_show_guessed_[0][i]))
        if (i % 5) == 3:
            RR_w.append(float(to_show_wanted_[0][i]) * 1700)
            RR_g.append(float(to_show_guessed_[0][i]) * 1700)
            RR_w_.append(float(to_show_wanted_[0][i]))
            RR_g_.append(float(to_show_guessed_[0][i]))
        if (i % 5) == 4:
            SW_w.append(float(to_show_wanted_[0][i]) / 60)
            SW_g.append(float(to_show_guessed_[0][i]) / 60)
            SW_w_.append(float(to_show_wanted_[0][i]))
            SW_g_.append(float(to_show_guessed_[0][i]))
            
    fig = plt.figure()
    ax1 = plt.subplot2grid((5, 1), (0, 0))
    ax2 = plt.subplot2grid((5, 1), (1, 0))
    ax3 = plt.subplot2grid((5, 1), (2, 0))
    ax4 = plt.subplot2grid((5, 1), (3, 0))
    ax5 = plt.subplot2grid((5, 1), (4, 0))
                           
    ax1.plot(FL_w, label="FL wanted")
    ax1.plot(FL_g, label="FL guessed")
    ax1.legend(loc=1)
    
    ax2.plot(FR_w, label="FR wanted")
    ax2.plot(FR_g, label="FR guessed")
    ax2.legend(loc=1)
    
    ax3.plot(RL_w, label="RL wanted")
    ax3.plot(RL_g, label="RL guessed")
    ax3.legend(loc=1)
    
    ax4.plot(RR_w, label="RR wanted")
    ax4.plot(RR_g, label="RR guessed")
    ax4.legend(loc=1)
    
    ax5.plot(SW_w, label="SW wanted")
    ax5.plot(SW_g, label="SW guessed")
    ax5.legend(loc=1)
    
    plt.show()
    

def inspect_segment(segment_num, train=False):
    if train:
        a, b = one_segment__train(segment_num)
        lets_see(a, b)
    else:
        a, b = one_segment__test(segment_num)
        lets_see(a, b)
    return a, b

the_segment = 10
to_show_wanted_glob, to_show_guessed_glob = inspect_segment(the_segment)

to_show_wanted_glob_array = to_show_wanted_glob.cpu().detach().numpy()
to_show_guessed_glob_array = to_show_guessed_glob.cpu().detach().numpy()
counted_MSE, counted_error = 0, 0
for i in range(0, len(to_show_guessed_glob_array[0])):
    counted_MSE += math.pow((to_show_wanted_glob_array[0][i] - to_show_guessed_glob_array[0][i]), 2)
    counted_error += abs(to_show_wanted_glob_array[0][i] - to_show_guessed_glob_array[0][i])
counted_MSE = counted_MSE / len(to_show_guessed_glob_array[0])
counted_error = counted_error / len(to_show_guessed_glob_array[0])
print("")
#print("Counted MSE = ", counted_MSE)
#print("Counted mean error =", counted_error)
given_MSE = loss_function(to_show_guessed_glob, to_show_wanted_glob)
print("MSE =", given_MSE)
    
