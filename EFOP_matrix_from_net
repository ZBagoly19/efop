# -*- coding: utf-8 -*-
"""
Created on Mon Apr 11 11:53:50 2022

@author: Bagoly Zolt치n
"""
import os
import numpy as np
import tqdm as my_tqdm
import torch
import torch.nn as nn
import torch.nn.functional as F
import time
import numpy as gfg

NET_TYPE =   "fully connected"   # "convolutional" or "fully connected"
TIME__ = 1649549122
epoch = 399
TRAINING_NAME = "efop__" + str(TIME__)
LABEL_NAME = f"fc__{int(time.time())}"
print("")
print(TRAINING_NAME)
device = torch.device("cpu")

# adat elokeszites
LEN_OF_SEGMENTS = 400
LEN_OF_INPUT = 4 * LEN_OF_SEGMENTS
LEN_OF_OUTPUT = 5 * LEN_OF_SEGMENTS
DATA_STRIDE = 10

shuffled_training_data = np.load("my_training_data_1d_XYVO_better_skale.npy", allow_pickle=True)
shuffled_testing_data = np.load("my_testing_data_1d_XYVO_better_skale.npy", allow_pickle=True)
my_X = torch.Tensor([i[0] for i in shuffled_training_data]).view(-1, LEN_OF_INPUT)
my_X_t = torch.Tensor([i[0] for i in shuffled_testing_data]).view(-1, LEN_OF_INPUT)
my_y = torch.Tensor([i[1] for i in shuffled_training_data]).view(-1, LEN_OF_OUTPUT)
my_y_t = torch.Tensor([i[1] for i in shuffled_testing_data]).view(-1, LEN_OF_OUTPUT)
my_test_X_l = my_X_t
my_test_y_l = my_y_t
my_train_X_l = my_X
my_train_y_l = my_y

my_test_X, my_test_y, my_train_X, my_train_y = my_test_X_l, my_test_y_l, my_train_X_l, my_train_y_l

# GPU
def on_gpu():
    if torch.cuda.is_available():
        return torch.device("cuda:0")
    else:
        return torch.device("cpu")

device = on_gpu()
print(device)

# Net convolutional
class Net_conv(nn.Module):
    def __init__(self):
        super().__init__()
        
        self.conv1 = nn.Conv1d(1, 32, kernel_size=4, stride=4)
        nn.init.kaiming_uniform_(self.conv1.weight, mode='fan_in', nonlinearity='relu')
        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, dilation=1, padding=2)
        nn.init.kaiming_uniform_(self.conv2.weight, mode='fan_in', nonlinearity='relu')
        self.conv3 = nn.Conv1d(64, 64, kernel_size=5, dilation=1, padding=2)
        nn.init.kaiming_uniform_(self.conv3.weight, mode='fan_in', nonlinearity='relu')
        self.conv4 = nn.Conv1d(64, 64, kernel_size=5, dilation=1, padding=2)
        nn.init.kaiming_uniform_(self.conv4.weight, mode='fan_in', nonlinearity='relu')
        self.conv5 = nn.Conv1d(64, 64, kernel_size=5, dilation=1, padding=2)
        nn.init.kaiming_uniform_(self.conv5.weight, mode='fan_in', nonlinearity='relu')
        
        self.conv6 = nn.Conv1d(16, 128, kernel_size=5, dilation=1, padding=2)
        nn.init.kaiming_uniform_(self.conv6.weight, mode='fan_in', nonlinearity='relu')
        self.conv7 = nn.Conv1d(128, 64, kernel_size=5, dilation=1, padding=2)
        nn.init.kaiming_uniform_(self.conv7.weight, mode='fan_in', nonlinearity='relu')
        
        x = torch.randn(LEN_OF_INPUT).view(-1, 1, LEN_OF_INPUT)
        self._to_linear = None
        self.convs(x)
        
        self.fc1 = nn.Linear(self._to_linear, 512)
        nn.init.kaiming_uniform_(self.fc1.weight, mode='fan_in', nonlinearity='relu')
        self.fc2 = nn.Linear(512, LEN_OF_OUTPUT)
        nn.init.kaiming_uniform_(self.fc2.weight, mode='fan_in', nonlinearity='relu')
        
    def convs(self, x):
        x = F.max_pool1d(F.relu(self.conv1(x)), (3))
        #print("\n")
        #print("1", x[0].shape, x[0], x)
        x = F.max_pool1d(F.relu(self.conv2(x)), (3))
        #print("2", x[0].shape, x[0], x)
        x = F.max_pool1d(F.relu(self.conv3(x)), (3))
        #x = F.max_pool1d(F.relu(self.conv4(x)), (3))
        #x = F.max_pool1d(F.relu(self.conv5(x)), (3))
        #x = F.max_pool1d(F.relu(self.conv6(x)), (3))
        #x = F.max_pool1d(F.relu(self.conv7(x)), (3))
        # hat ezt kiszamolni nem lett volna konnyu. Ezert kell kiprobalni random adattal
        
        if self._to_linear == None:
            self._to_linear = x[0].shape[0] * x[0].shape[1]

        return x
        
    def forward(self, x):
        # print(self.only_linear)
        x = self.convs(x)
        # print("3", x.shape, x[0], x)
        
        x = x.view(-1, self._to_linear)
        # print("4", x.shape, x[0], x)
        
        x = F.relu(self.fc1(x))
        # print("5", x.shape, x[0], x)
                
        x = self.fc2(x)
        # print("6", x.shape, x[0], x)
        
        return x

# Net fully connected
class Net_fc(nn.Module):
    def __init__(self):
        super().__init__()
        
        x = torch.randn(LEN_OF_INPUT).view(-1, 1, LEN_OF_INPUT)
        self._to_linear = None
        self.linearize(x)
        
        self.fc1 = nn.Linear(self._to_linear, 2048)
        nn.init.kaiming_uniform_(self.fc1.weight, mode='fan_in', nonlinearity='relu')
        self.fc2 = nn.Linear(2048, 2048)
        nn.init.kaiming_uniform_(self.fc2.weight, mode='fan_in', nonlinearity='relu')
        self.fc3 = nn.Linear(2048, 2048)
        nn.init.kaiming_uniform_(self.fc3.weight, mode='fan_in', nonlinearity='relu')
        self.fc4 = nn.Linear(2048, 2048)
        nn.init.kaiming_uniform_(self.fc4.weight, mode='fan_in', nonlinearity='relu')
        self.fc5 = nn.Linear(2048, 2048)
        nn.init.kaiming_uniform_(self.fc5.weight, mode='fan_in', nonlinearity='relu')
        self.fc6 = nn.Linear(2048, 2048)
        nn.init.kaiming_uniform_(self.fc6.weight, mode='fan_in', nonlinearity='relu')
        self.fc7 = nn.Linear(2048, 2048)
        nn.init.kaiming_uniform_(self.fc7.weight, mode='fan_in', nonlinearity='relu')
        self.fc8 = nn.Linear(2048, 2048)
        nn.init.kaiming_uniform_(self.fc8.weight, mode='fan_in', nonlinearity='relu')
        self.fc9 = nn.Linear(2048, 2048)
        nn.init.kaiming_uniform_(self.fc9.weight, mode='fan_in', nonlinearity='relu')
        self.fc10 = nn.Linear(2048, 2048)
        nn.init.kaiming_uniform_(self.fc10.weight, mode='fan_in', nonlinearity='relu')
        self.fc11 = nn.Linear(2048, 2048)
        nn.init.kaiming_uniform_(self.fc9.weight, mode='fan_in', nonlinearity='relu')
        self.fc12 = nn.Linear(2048, 2048)
        nn.init.kaiming_uniform_(self.fc10.weight, mode='fan_in', nonlinearity='relu')
        self.fc_last = nn.Linear(2048, LEN_OF_OUTPUT)
        nn.init.kaiming_uniform_(self.fc_last.weight, mode='fan_in', nonlinearity='relu')
                
    def linearize(self, x):
        if self._to_linear == None:
            self._to_linear = x[0].shape[0] * x[0].shape[1]

        return x
        
    def forward(self, x):
        # print("33", x.shape, x[0], x)
        
        x = x.view(-1, self._to_linear)
        # print("4", x.shape, x[0], x)
        
        x = F.relu(self.fc1(x))
        # print("5", x.shape, x[0], x)
        
        x = F.relu(self.fc2(x))
        # print("6", x.shape, x[0], x)
        
        x = F.relu(self.fc3(x))
        # print("7", x.shape, x[0], x)
        
        x = F.relu(self.fc4(x))
        # print("8", x.shape, x[0], x)
        
        x = F.relu(self.fc5(x))
        #print("9", x.shape, x[0], x)
        
        x = F.relu(self.fc6(x))
        #print("10", x.shape, x[0], x)
        
        x = F.relu(self.fc7(x))
        #print("11", x.shape, x[0], x)
        
        x = F.relu(self.fc8(x))
        #print("12", x.shape, x[0], x)
        
        x = F.relu(self.fc9(x))
        #print("13", x.shape, x[0], x)
        
        x = F.relu(self.fc10(x))
        #print("14", x.shape, x[0], x)
                
        x = F.relu(self.fc11(x))
        #print("15", x.shape, x[0], x)
        
        x = F.relu(self.fc12(x))
        #print("16, x.shape, x[0], x)
        
        x = self.fc_last(x)
        # print("last", x.shape, x[0], x)
        
        return x

def load_net(path_param):
    if os.path.isfile(path_param):
        print("helyes filenev:", path_param)
        
        net = torch.load(os.path.join(path_param))
        print(net)
        net.eval()

loss_function = nn.MSELoss()
MODEL_NUMBER = 1
print("pr칩ba:", 'net_{}.pth'.format(TIME__ *100000 + MODEL_NUMBER *1000 + epoch))
# while os.path.isfile(os.path.join('net_{}.pth'.format(TIME__ *100000 + MODEL_NUMBER *1000 + epoch))):
if os.path.isfile(os.path.join('net_{}.pth'.format(TIME__ *100000 + MODEL_NUMBER *1000 + epoch))):
    print("betoltott h치l칩", os.path.join('net_{}.pth'.format(TIME__ *100000 + MODEL_NUMBER *1000 + epoch)))
    
    net = torch.load(os.path.join('net_{}.pth'.format(TIME__ *100000 + MODEL_NUMBER *1000 + epoch)))
    net.eval()
    
    def my_test(size=64, print_now=False):
        # print(my_test_X.shape, my_test_X)
        # print("len(my_test_X)", len(my_test_X))
        # print(size)
        random_start = np.random.randint(len(my_test_X) - size)
        
        my_X2, my_y2 = my_test_X[random_start : random_start + size], my_test_y[random_start : random_start + size]
        net.eval()
        with torch.no_grad():
            val_acc, val_loss = my_fwd_pass(my_X2.view(-1, 1, LEN_OF_INPUT).to(device), my_y2.to(device), train=False)
        if(print_now):
            print("Val loss: ", val_loss, "; Val_acc: ", val_acc)
        net.train()
        return val_acc, val_loss
    
    def my_fwd_pass(b_x, b_y, train=False):
        if train == True:
            net.zero_grad()
        #print("b_x", b_x.shape)
        #print("b_y:", b_y.shape)
        outputs = net(b_x)
        #print("outputs: ", outputs.shape, outputs)
        # if train == False:
            # print("outputs:", outputs, "\nb_y:", b_y)
        # a matches-t maskepp kene szamolni
        matches = [abs(torch.argmax(i) - torch.argmax(j)) < 0.1 for i, j in zip(outputs, b_y)]
        accuracy = matches.count(True) / len(matches)
        loss = loss_function(outputs, b_y)
    
        # with open("efop_log_output_of_net.log", "a") as file:
        #     # for i in range(len(outputs)):
        #     #     output = outputs[0][i]
        #     file.write(f"{MODEL_NAME},{round(time.time(),3)},{round(float(outputs),10)}\n")
        #     file.write(f"{MODEL_NAME},{round(time.time(),3)},{round(float(loss),15)}\n")
        return accuracy, loss
    
    model_name = TRAINING_NAME
    
    def one_segment_test(start, print_loss=False):
        # print(start)
        my_X3, my_y3 = my_test_X[start : start + 1], my_test_y[start : start + 1]
        to_show_wanted = my_y3.to(device)
        to_show_guessed = net(my_X3.view(-1, 1, LEN_OF_INPUT).to(device))
        # print(to_show_wanted.shape)
        # print(to_show_guessed.shape)
        # print(" Target:", to_show_wanted, "\n", "Guess:", to_show_guessed)
        loss = loss_function(to_show_guessed, to_show_wanted)
        if print_loss:
            print(loss)
        return to_show_wanted, to_show_guessed
    def one_segment_test_on_train(start):
        # print(start)
        my_X3, my_y3 = my_train_X[start : start + 1], my_train_y[start : start + 1]
        to_show_wanted = my_y3.to(device)
        to_show_guessed = net(my_X3.view(-1, 1, LEN_OF_INPUT).to(device))
        # print(to_show_wanted.shape)
        # print(to_show_guessed.shape)
        # print(" Target:", to_show_wanted, "\n", "Guess:", to_show_guessed)
        return to_show_wanted, to_show_guessed
    
    def create_matrices():
        matrix_test = np.empty([1, LEN_OF_OUTPUT * 2], dtype=int)
        for seg in my_tqdm.tqdm(range(0, len(my_test_X), 1)):
            wanted, guessed = one_segment_test(seg)
            a = wanted.cpu()
            b = guessed.cpu()
            c = a.detach().numpy()
            d = b.detach().numpy()
            matrix_row = np.column_stack([c, d])
            matrix_test = np.append(matrix_test, matrix_row, axis=0)
        matrix_test = np.delete(matrix_test, 0, 0)
    
        matrix_train = np.empty([1, LEN_OF_OUTPUT * 2], dtype=int)
        for seg in my_tqdm.tqdm(range(0, len(my_train_X), 1)):
            wanted, guessed = one_segment_test_on_train(seg)
            a = wanted.cpu()
            b = guessed.cpu()
            c = a.detach().numpy()
            d = b.detach().numpy()
            matrix_row = np.column_stack([c, d])
            matrix_train = np.append(matrix_train, matrix_row, axis=0)
        matrix_train = np.delete(matrix_train, 0, 0)
        
        return matrix_test, matrix_train
    
    matrix_test_g, matrix_train_g =  create_matrices()
            
    gfg.savetxt("matrix_test.txt", matrix_test_g)
    gfg.savetxt("matrix_train.txt", matrix_train_g)
